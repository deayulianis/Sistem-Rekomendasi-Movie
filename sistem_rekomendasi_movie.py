# -*- coding: utf-8 -*-
"""Sistem Rekomendasi Movie.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SddYRm7l2d01T7b51_ddDqkei5oZT5lw

# Proyek Machine Learning - Dea Yuliani Sabrina

# Project Overview

Rekomendasi film sangat penting untuk membantu pengguna menemukan film yang relevan dengan preferensi mereka.
Sistem rekomendasi ini dibangun dengan memanfaatkan dataset MovieLens, yang berisi rating dan metadata film.
Masalah ini harus diselesaikan untuk:
- Meningkatkan kepuasan pengguna (user satisfaction)
- Mempermudah pengguna menemukan film baru yang sesuai

**Referensi:** [Ricci, F., Rokach, L., & Shapira, B. (2015). Recommender Systems Handbook (2nd ed.). Springer.](https://doi.org/10.1007/978-1-4899-7637-6)

# Business Understanding

**Problem Statements**

1)  Bagaimana cara merekomendasikan film yang sesuai dengan preferensi setiap pengguna secara otomatis?

2) Bagaimana memahami preferensi pengguna hanya berdasarkan film yang telah mereka tonton dan beri rating?

3) Bagaimana menyarankan film baru yang belum ditonton pengguna, namun relevan dengan minat mereka?

**Goals:**

1) Membangun sistem rekomendasi film yang mampu memberikan saran film secara otomatis dan personal untuk setiap pengguna.

2) Menggunakan riwayat rating film dari pengguna untuk memahami dan membentuk profil preferensi genre mereka.

3)  Menghasilkan rekomendasi film yang belum ditonton user namun memiliki kemiripan genre tinggi dengan film yang mereka sukai sebelumnya.


**Solution Approach:**
- Collaborative Filtering: menggunakan matrix factorization (SVD)
- Content-Based Filtering: menggunakan cosine similarity antara metadata film (genre)

# Data Understanding

Dataset yang digunakan dalam proyek ini merupakan dataset tentang Movie. Dataset ini dapat diunduh di [Kaggle:MovieLens Latest Small](https://www.kaggle.com/datasets/grouplens/movielens-latest-small)
"""

# Import module yang disediakan google colab untuk kebutuhan upload file
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Ganti 'username' dan 'dataset-name' sesuai dengan dataset yang kamu pakai
!kaggle datasets download -d grouplens/movielens-latest-small
!unzip movielens-latest-small.zip -d movielens-latest-small

import pandas as pd

# Membaca dataset dari file CSV
links = pd.read_csv('/content/movielens-latest-small/links.csv')
movies = pd.read_csv('/content/movielens-latest-small/movies.csv')
ratings = pd.read_csv('/content/movielens-latest-small/ratings.csv')
tags = pd.read_csv('/content/movielens-latest-small/tags.csv')

# Menampilkan jumlah data unik untuk analisis awal
print('Jumlah total film di dataset movies: ', len(movies.movieId.unique()))
print('Jumlah genre unik yang tersedia: ', len(set('|'.join(movies.genres).split('|'))))  # gabungan semua genre

print('Jumlah user yang memberikan rating: ', len(ratings.userId.unique()))
print('Jumlah film yang memiliki rating: ', len(ratings.movieId.unique()))
print('Jumlah total rating: ', len(ratings))

print('Jumlah user yang memberi tag: ', len(tags.userId.unique()))
print('Jumlah film yang diberi tag: ', len(tags.movieId.unique()))
print('Jumlah total tag: ', len(tags))

print('Jumlah film yang memiliki data IMDb (di links): ', len(links.movieId.unique()))
print('Jumlah data di links: ', len(links))

"""dari output didapat:
1. Informasi dari Dataset movies.csv
- Ada 9.742 film unik yang tercatat dalam dataset movies. Setiap baris merepresentasikan satu film berdasarkan movieId.
- Total ada 20 genre berbeda (seperti Action, Drama, Comedy, dll). Genre di dataset biasanya disimpan dalam satu kolom dan dipisahkan dengan tanda |, misalnya Action|Adventure.

2. Informasi dari Dataset ratings.csv
- Sebanyak 610 pengguna unik telah memberikan rating.
- Dari 9742 film di dataset, 9724 film sudah pernah dirating oleh pengguna, artinya hanya 18 film belum mendapat rating.
- Terdapat 100.836 rating, yang merupakan jumlah semua rating dari seluruh user terhadap berbagai film.

3. Informasi dari Dataset tags.csv
- Hanya 58 user yang memberi tag (label/kata kunci deskriptif) terhadap film — lebih sedikit dibanding user yang memberi rating.
- Sebanyak 1.572 film telah diberi tag oleh pengguna. Sisanya tidak memiliki informasi tag.
- Terdapat 3.683 baris tag, artinya satu film bisa memiliki lebih dari satu tag, dan satu user bisa memberi tag ke beberapa film.

4. Informasi dari Dataset links.csv
- Semua 9742 film memiliki data IMDb (link ke ID IMDb) — tidak ada yang hilang. File ini biasanya digunakan untuk menghubungkan movieId ke ID eksternal seperti IMDb atau TMDb.

# Univariate Exploratory Data Analysis

| Dataset   | Variabel | Fungsi Utama |
|-------------|-----------|------------|
| links     | movieId, imdbId   | Hubungkan movieId ke data eksternal (IMDb) |
| movies       | movieId, title, genres    | Informasi konten film |
| ratings     | userId, movieId, rating, timestamp    | Interaksi user (untuk collaborative filtering) |
|tags| userId, movieId, tag, timestamp|Tag/kata kunci user (bisa untuk content-based)|

## ratings.csv
"""

ratings.head()

"""Melihat 5 data teratas dari dataset rating.csv"""

ratings.info()

"""dari output didapat:
- Dataset terdiri dari 100.836 baris dan 4 kolom.
- Semua kolom tidak ada yang kosong (non-null).
- Kolom userId, movieId, dan timestamp bertipe integer, sedangkan rating adalah float.
- Kolom:
1. **userId:** ID unik pengguna.

2. **movieId:** ID unik film.

3. **rating:** Nilai rating yang diberikan (0.5 – 5.0).

4. **timestamp:** Waktu saat rating diberikan (dalam format UNIX time).
"""

# Jumlah user unik
print("Jumlah user unik:", ratings['userId'].nunique())

"""Total ada 610 pengguna berbeda yang memberikan rating terhadap film."""

# Jumlah film unik yang diberi rating
print("Jumlah film unik:", ratings['movieId'].nunique())

"""Ada 9.724 film berbeda yang menerima setidaknya satu rating.Ini menunjukkan sebaran data rating sudah cukup luas ke berbagai film."""

# Statistik deskriptif rating
print("\nStatistik rating:")
print(ratings['rating'].describe())

"""dari output didapat:

- Mayoritas rating ada di rentang 3.0–4.0.

- Rating cenderung positif (rata-rata 3.5).

- Tidak ada rating di bawah 0.5 atau di atas 5.0 → data valid.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Distribusi rating
plt.figure(figsize=(8,5))
sns.countplot(x='rating', data=ratings)
plt.title("Distribusi Rating")
plt.xlabel("Rating")
plt.ylabel("Jumlah")
plt.show()

"""dari grafik didapat:

- Rating 4.0 paling banyak diberikan.

- Disusul 3.0, lalu 5.0 → pengguna lebih sering memberi nilai tinggi.

- Rating 0.5 dan 1.0 relatif jarang → menunjukkan bias pengguna terhadap hal-hal yang disukai.
"""

# Rata-rata rating per film (top 10 film)
mean_ratings = ratings.groupby('movieId')['rating'].mean().sort_values(ascending=False).head(10)
print("\n10 Film dengan rating rata-rata tertinggi:")
print(mean_ratings)

"""dari output didapat:

- 10 film ini punya rata-rata rating 5.0 → artinya setiap rating yang masuk nilainya maksimal.

- Kemungkinan film ini hanya punya 1 atau sedikit rating, jadi rata-ratanya belum mewakili banyak opini.

- Perlu dicek jumlah ratingnya untuk memastikan mereka benar-benar populer atau hanya disukai oleh 1–2 pengguna saja.
"""

# Menghitung jumlah rating per film
rating_counts = ratings.groupby('movieId')['rating'].count()

# Mengurutkan dari yang paling banyak diberi rating
top_rated_movies = rating_counts.sort_values(ascending=False).head(10)

print("10 Film dengan jumlah rating terbanyak:")
print(top_rated_movies)

"""dari output didapat:
- Ini adalah film-film paling sering dirating oleh user, jadi bisa disebut film paling populer di dataset.

- Misalnya, film dengan movieId = 356 memiliki 329 rating, berarti banyak user yang menonton dan menilainya.
"""

# Hitung jumlah rating dan rata-rata rating per film
rating_summary = ratings.groupby('movieId')['rating'].agg(['mean', 'count'])

# Filter film yang memiliki minimal 100 rating
popular_and_high_rated = rating_summary[rating_summary['count'] >= 100]

# Urutkan berdasarkan rata-rata rating tertinggi
best_movies = popular_and_high_rated.sort_values('mean', ascending=False).head(10)

print("10 Film terbaik berdasarkan rata-rata rating (minimal 100 rating):")
print(best_movies)

"""dari output didapat:

- Ini adalah film dengan kualitas terbaik berdasarkan rating rata-rata, dengan syarat jumlah rating-nya ≥ 100.

- Jadi, film seperti movieId = 318 tidak hanya populer (317 rating), tapi juga sangat disukai (rating rata-rata 4.42).

## movies.csv
"""

movies.head()

"""Melihat 5 data teratas dari dataset movies.csv"""

movies.info()

"""dari output didapat:
- Dataset terdiri dari 9742 baris dan 3 kolom.
- Semua kolom tidak ada yang kosong (non-null).
- Kolom movieId bertipe integer, sedangkan title dan genres adalah string (object).
- Kolom:
1. **movieId:** ID unik film.

2. **title:** Judul film.

3. **genres:** Genre film.
"""

# Pisahkan semua genre
from collections import Counter

all_genres = movies['genres'].str.split('|').sum()
genre_counts = Counter(all_genres)

# Tampilkan 10 genre terbanyak
print("10 Genre paling banyak muncul:")
print(genre_counts.most_common(10))

"""dari output didapat:
- Genre Drama adalah yang paling umum, muncul dalam 4.361 film.

- Diikuti oleh Comedy, Thriller, dan Action.

- Ini dihitung dengan memecah isi kolom genres berdasarkan tanda |, lalu dijumlahkan total kemunculan genre.
"""

# Ekstrak tahun dari title
import re

movies['year'] = movies['title'].str.extract(r'\((\d{4})\)').astype(float)

# Cek distribusi film per tahun
movies_per_year = movies['year'].value_counts().sort_index()

print("Jumlah film per tahun (top 10 tahun terbanyak):")
print(movies_per_year.tail(10))

"""dari output didapat:

- Tahun diambil dari kolom title menggunakan regex \((\d{4})\) untuk menangkap angka tahun dalam tanda kurung.

- Jumlah film paling banyak di tahun 2009 (282 film).

- Setelah 2015 jumlah film mulai menurun — kemungkinan karena data film yang lebih baru belum lengkap di dataset ini.

# Data Preparation

### Gabung movies dan ratings
"""

# Menggabungkan berdasarkan 'movieId'
movie_ratings = pd.merge(ratings, movies, on='movieId')

# Lihat 5 data teratas
movie_ratings.head()

"""dari output didapat:

- Dataset baru movie_ratings sekarang mengandung semua kolom dari ratings dan juga title, genres, serta year dari movies.

- Ini membuat analisis lebih fleksibel: kita bisa filter berdasarkan genre, tahun, dll sekaligus melihat rating.

### Cek Missing Values dan Menanganinya
"""

print("Jumlah missing values per kolom:")
movie_ratings.isnull().sum()

"""dari output didapat:

- Hanya kolom year yang punya 18 missing values, karena tidak semua judul film memiliki tahun di title.

- Nanti bisa drop atau isi dengan strategi tertentu (misalnya dengan median atau kategori “unknown”).
"""

# Tangani Missing Value (contoh: drop baris dengan year kosong)
movie_ratings_clean = movie_ratings.dropna(subset=['year'])

"""Menghapus baris yang tidak memiliki tahun rilis karena bisa mengganggu analisis time series atau tren per tahun."""

# Cek kembali
movie_ratings_clean.isnull().sum()

"""Data sudah bersih dari Missing Value

### Ubah tahun jadi integer
"""

movie_ratings_clean['year'] = movie_ratings_clean['year'].astype(int)

"""Kode ini digunakan untuk mengubah tipe data kolom year menjadi integer (int)."""

movie_ratings_clean.info()

"""pada kolom year udah berubah data typenya menjadi integer dari float

### Buat kolom genre terpisah
"""

# Pisah genre menjadi beberapa kolom (multi-label binarizer)
from sklearn.preprocessing import MultiLabelBinarizer

# Ubah kolom genre jadi list
movie_ratings_clean['genres'] = movie_ratings_clean['genres'].apply(lambda x: x.split('|'))

mlb = MultiLabelBinarizer()
genre_encoded = pd.DataFrame(mlb.fit_transform(movie_ratings_clean['genres']), columns=mlb.classes_)

# Gabungkan dengan data asli
movie_ratings_final = pd.concat([movie_ratings_clean, genre_encoded], axis=1)

# Cek hasil akhir
movie_ratings_final.head()

"""dari output didapat:

- Kolom genres sekarang adalah list, bukan string.

- Kolom-kolom tambahan di akhir (Action, Comedy, ..., Western) adalah hasil binarisasi.

- Berisi angka 0 dan 1 yang menunjukkan apakah film tersebut mengandung genre tersebut.

Contoh:

- Toy Story (1995) memiliki nilai 1 di kolom Adventure, Animation, Children, dll.

- Heat (1995) memiliki 1 di Action, Crime, dan Thriller.

# Modeling

### Content-Based Filtering dengan pendekatan User Profile Genre

Cara Kerja:

“Jika user menyukai film bergenre Action dan Sci-Fi, maka film lain dengan genre serupa akan lebih disukai.”

✅ Kelebihan:
- Tidak tergantung user lain: Hanya butuh data user itu sendiri → cocok untuk sistem individual.

- Bekerja baik untuk cold-start user: Karena memanfaatkan metadata (genre), model masih bisa memberikan rekomendasi walau user belum banyak memberi rating.

- Rekomendasi dapat dijelaskan: Misalnya: “Film ini direkomendasikan karena memiliki genre Action dan Sci-Fi yang Anda sukai.”

- Lebih stabil terhadap perubahan data: Tidak terlalu terpengaruh oleh fluktuasi data rating user lain.

❌ Kekurangan:
- Rekomendasi cenderung sempit: User hanya mendapat rekomendasi yang mirip dengan yang sudah ditonton → kurang bisa eksplorasi genre/film baru.

- Kualitas tergantung metadata: Jika informasi genre tidak lengkap atau tidak relevan, kualitas rekomendasi bisa buruk.

- Tidak menangkap selera kompleks: Tidak mempertimbangkan bagaimana user lain menilai film serupa.
"""

# Hitung preferensi genre tiap user
user_profiles = movie_ratings_final.groupby('userId')[mlb.classes_].mean()
user_profiles.head()

"""dari output didapat:

- Output user_profiles adalah representasi minat setiap pengguna terhadap genre film dalam bentuk vektor.

- Nilai pada tabel adalah rata-rata kehadiran genre dalam film yang ditonton user.

- Semakin tinggi nilainya (mendekati 1), berarti user lebih sering menonton film dengan genre tersebut.
"""

# Ambil data user tertentu
target_user_id = 1.0  # Sesuaikan tipe data dengan user_profiles.index
user_profile = user_profiles.loc[target_user_id]

# Drop film yang sudah ditonton user
user_watched = movie_ratings_final[movie_ratings_final['userId'] == target_user_id]['movieId'].unique()
unwatched_movies = movie_ratings_final[~movie_ratings_final['movieId'].isin(user_watched)].drop_duplicates('movieId')

# Hitung kemiripan skor antara preferensi user dan genre film
# Pastikan hanya kolom genre yang digunakan
genre_columns = mlb.classes_
unwatched_movies['similarity'] = unwatched_movies[genre_columns].dot(user_profile[genre_columns])

# Ambil 10 film dengan skor kemiripan tertinggi
recommended_movies = unwatched_movies.sort_values('similarity', ascending=False)[['title', 'similarity']].head(10)

# Tampilkan rekomendasi
print(f"Rekomendasi untuk User ID {int(target_user_id)}:")
print(recommended_movies)

"""dari output didapat:

- Ini adalah implementasi content-based filtering menggunakan genre sebagai fitur konten film.

- Rekomendasi diberikan berdasarkan kemiripan antara film dan preferensi user, bukan karena film itu populer atau disukai user lain (bukan collaborative).

## Skor Kemiripan → Top-N Rekomendasi
"""

# Tentukan user ID target
user_id = 1

# Buat profil user dari genre
user_profiles = movie_ratings_final.groupby('userId')[mlb.classes_].mean()
user_profile = user_profiles.loc[user_id]

# Ambil film yang belum ditonton user
user_watched = movie_ratings_final[movie_ratings_final['userId'] == user_id]['movieId']
unwatched_movies_cb = movie_ratings_final[~movie_ratings_final['movieId'].isin(user_watched)].drop_duplicates('movieId')

# Hitung kemiripan (dot product antara profil user dan genre film)
unwatched_movies_cb['similarity'] = unwatched_movies_cb[mlb.classes_].dot(user_profile)

# Ambil Top-N film dengan skor kemiripan tertinggi
top_n_cb = unwatched_movies_cb.sort_values('similarity', ascending=False).head(10)
print("\nTop-N Rekomendasi berdasarkan Skor Kemiripan Genre:")
print(top_n_cb[['movieId', 'title', 'similarity']])

"""✅ Film yang direkomendasikan memiliki skor kemiripan tinggi terhadap profil genre user, artinya sistem berhasil menangkap pola kesukaan genre dari histori tontonan user.

✅Film rekomendasi berasal dari berbagai dekade (1973, 1988, 2007, 2016), menunjukkan bahwa sistem tidak memprioritaskan tahun rilis, tetapi kesesuaian genre.

✅Judul film seperti "I'm a Cyborg, But That's OK" atau "Last Life in the Universe" kurang populer, namun direkomendasikan karena genre-nya sangat cocok dengan selera user.

✅Sistem dapat mengusulkan film internasional

✅ Film animasi atau keluarga juga muncul jika genre relevan

### Collaborative Filtering (Matrix Factorization – SVD)

Cara Kerja:

“Jika user A dan user B memiliki rating mirip untuk banyak film, maka film yang disukai B dan belum ditonton A bisa direkomendasikan ke A.”

✅ Kelebihan:
- Personalized: Rekomendasi lebih akurat karena memperhitungkan pola interaksi antar pengguna dan item.

- Tidak membutuhkan metadata film: Cukup menggunakan data userId, movieId, dan rating saja.

- Menemukan hubungan tersembunyi: Dapat mengenali preferensi user meskipun genre atau konten film tidak diketahui secara eksplisit.

- Skalabilitas tinggi dengan matrix factorization (SVD): Efisien dalam menangani data besar dengan teknik pemfaktoran.

❌ Kekurangan:
- Cold Start Problem:

- User baru: Tidak ada cukup data riwayat untuk merekomendasikan film.

- Item baru: Film yang belum pernah diberi rating tidak bisa direkomendasikan.

- Sparsity (Kerapatan rendah): Matrix user-item bisa sangat besar tapi banyak yang kosong → mempengaruhi akurasi model.

- Tidak menjelaskan alasan rekomendasi: Sulit dimengerti mengapa film tersebut direkomendasikan.
"""

pip install scikit-surprise

!pip install numpy==1.24.4

"""
Tujuan:

* *Menjamin kompatibilitas* antara NumPy dan library lain dalam proyek (misalnya, scikit-learn, pandas, atau surprise untuk collaborative filtering).
* Beberapa library mungkin *tidak kompatibel dengan versi NumPy terbaru, sehingga versi 1.24.4 dipilih untuk **menghindari error atau bug* saat menjalankan model rekomendasi atau matrix factorization."""

from surprise import Dataset, Reader, SVD
from surprise.model_selection import cross_validate

# Siapkan data untuk library surprise
reader = Reader(rating_scale=(0.5, 5.0))
data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)

# Latih model SVD
model = SVD()
cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

"""dari output didapat:

- Model SVD cukup stabil, dengan RMSE sekitar 0.87 dan MAE sekitar 0.67.

- Variasi hasil antar fold rendah (standar deviasi kecil), artinya model konsisten di berbagai subset data.

- Waktu pelatihan dan prediksi relatif cepat (beberapa detik dan kurang dari satu detik).

- Model sudah cukup baik untuk tugas prediksi rating film.

"""

model.fit(data.build_full_trainset())
pred = model.predict(1, 50)
print(pred.est)  # Ini prediksi rating

"""model memprediksi user 1 akan memberi rating 4.73 untuk movie 50 (dalam skala rating 0.5-5.0). Jadi, prediksi rating ini cukup tinggi dan menunjukkan bahwa user kemungkinan besar suka dengan film tersebut.

## Prediksi Rating → Top-N Rekomendasi
"""

# Daftar semua movieId
all_movie_ids = ratings['movieId'].unique()

# Daftar movieId yang sudah ditonton user
watched_movie_ids = ratings[ratings['userId'] == 1]['movieId'].unique()

# MovieId yang belum ditonton user
unwatched_movie_ids = [mid for mid in all_movie_ids if mid not in watched_movie_ids]

# Prediksi rating untuk semua movieId yang belum ditonton
predictions = [model.predict(uid=1, iid=mid) for mid in unwatched_movie_ids]

# Urutkan berdasarkan rating prediksi tertinggi
predictions.sort(key=lambda x: x.est, reverse=True)

# Ambil Top-10 rekomendasi
top_10_recommendations = predictions[:10]

# Tampilkan hasil
print("Top-10 rekomendasi untuk User ID 1:")
for pred in top_10_recommendations:
    movie_title = movies[movies['movieId'] == pred.iid]['title'].values[0]
    print(f"Movie: {movie_title}, Predicted Rating: {round(pred.est, 2)}")

"""✅ Top-10 film yang belum ditonton oleh User ID 1.

✅ Prediksi ratingnya 5.0 untuk semua film (tinggi banget!).

✅ Artinya, model sangat yakin bahwa User ID 1 akan sangat menyukai film-film ini.

# Evaluation

### Content-Based Filtering dengan pendekatan User Profile Genre
"""

# Tampilkan rekomendasi untuk user tertentu
print("Rekomendasi untuk User ID 1:")
print(recommended_movies)

# Cek genre yang sering muncul pada film yang ditonton user
user_movies = movie_ratings_final[movie_ratings_final['userId'] == target_user_id]
top_genres = user_movies[mlb.classes_].mean().sort_values(ascending=False).head(5)
print("\nTop genre dari film yang ditonton user:")
print(top_genres)

# Bandingkan dengan genre film yang direkomendasikan
rec_genres = unwatched_movies[unwatched_movies['movieId'].isin(recommended_movies.index)][mlb.classes_].mean().sort_values(ascending=False).head(5)
print("\nGenre dominan dari film yang direkomendasikan:")
print(rec_genres)

"""✅ Model rekomendasi menyesuaikan genre film rekomendasi dengan genre yang sering ditonton user 1.

✅ Terlihat konsistensi: Top genre yang disukai user (Action, Adventure, Comedy, Drama, Thriller) juga muncul pada rekomendasi.

✅ Adventure muncul dominan (1.0), artinya model sangat yakin film ini cocok dengan preferensi user.

## recision@K, Recall@K, NDCG@K
"""

# Fungsi evaluasi untuk Precision@K dan Recall@K
def precision_at_k(recommended, relevant, k):
    recommended_k = recommended[:k]
    relevant_set = set(relevant)
    hits = sum([1 for movie in recommended_k if movie in relevant_set])
    return hits / k if k > 0 else 0

def recall_at_k(recommended, relevant, k):
    recommended_k = recommended[:k]
    relevant_set = set(relevant)
    hits = sum([1 for movie in recommended_k if movie in relevant_set])
    return hits / len(relevant_set) if relevant_set else 0

# Pastikan variabel target_user_id dan recommended_movies sudah tersedia
target_user_id = 1  # bisa diganti dengan user lain

# Ambil daftar rekomendasi Content-Based (gunakan index, bukan kolom)
recommended_ids = recommended_movies.index.tolist()

# Ambil daftar film relevan (yang disukai user) berdasarkan rating >= 4
liked_movies = ratings[(ratings['userId'] == target_user_id) & (ratings['rating'] >= 4.0)]
relevant_ids = liked_movies['movieId'].tolist()

# Hitung metrik evaluasi
k = 10
precision = precision_at_k(recommended_ids, relevant_ids, k)
recall = recall_at_k(recommended_ids, relevant_ids, k)

# Tampilkan hasil evaluasi
print(f"\nEvaluasi Content-Based Filtering untuk User ID {target_user_id}")
print(f"Precision@{k}: {round(precision, 4)}")
print(f"Recall@{k}:    {round(recall, 4)}")


# Fungsi untuk menghitung DCG@K
def dcg_at_k(recommended, relevant, k):
    dcg = 0.0
    for i, movie_id in enumerate(recommended[:k]):
        if movie_id in relevant:
            dcg += 1 / np.log2(i + 2)  # log2(i+2) karena i mulai dari 0
    return dcg

# Fungsi untuk menghitung IDCG@K (ideal DCG)
def idcg_at_k(relevant, k):
    relevant_k = min(len(relevant), k)
    return sum([1 / np.log2(i + 2) for i in range(relevant_k)])

# Fungsi untuk menghitung NDCG@K
def ndcg_at_k(recommended, relevant, k):
    dcg = dcg_at_k(recommended, relevant, k)
    idcg = idcg_at_k(relevant, k)
    return dcg / idcg if idcg > 0 else 0

# Hitung NDCG@K
ndcg = ndcg_at_k(recommended_ids, relevant_ids, k)

# Tampilkan hasil
print(f"NDCG@{k}:     {round(ndcg, 4)}")

"""📌 Inti kode:

1️⃣ Hitung precision & recall pada 10 rekomendasi teratas.

2️⃣ Precision = berapa dari top-10 yang relevan.

3️⃣ Recall = proporsi film relevan yang berhasil direkomendasikan.

📌 Output 0.0 menunjukkan:

Artinya tidak ada film relevan (yang disukai user 1, rating ≥ 4) yang muncul di top-10 rekomendasi.

### Collaborative Filtering (Matrix Factorization – SVD)
"""

from surprise import Dataset, Reader, SVD
from surprise.model_selection import cross_validate

# Siapkan data untuk Surprise
reader = Reader(rating_scale=(0.5, 5.0))
data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)

# Buat model dan evaluasi dengan cross-validation
model = SVD()
evaluation = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

# Tampilkan hasil evaluasi
print("\nHasil Evaluasi Collaborative Filtering:")
print("Rata-rata RMSE:", round(evaluation['test_rmse'].mean(), 4))
print("Rata-rata MAE :", round(evaluation['test_mae'].mean(), 4))

# Fit model dan prediksi rating untuk userId 1 dan movieId 50
trainset = data.build_full_trainset()
model.fit(trainset)

prediction = model.predict(uid=1, iid=50)
print(f"\nPrediksi rating userId=1 untuk movieId=50: {round(prediction.est, 2)}")

"""✅ Model SVD sudah berjalan baik (dengan RMSE ~0.87).

✅ Prediksi rating untuk film movieId=50 sangat tinggi (5.0), jadi ini kandidat rekomendasi yang kuat untuk user 1.

## 🔍 Evaluation & Business Understanding

### 🎯 Problem Statement 1:
**Bagaimana cara merekomendasikan film yang sesuai dengan preferensi setiap pengguna secara otomatis?**

**Evaluasi:**
- Algoritma **Collaborative Filtering (SVD)** diuji menggunakan metrik **RMSE** dan **MAE**.
- Hasil rata-rata error menunjukkan bahwa sistem dapat memperkirakan rating dengan cukup akurat.

**Dampak:**
- Model ini mampu memberikan rekomendasi otomatis dan personal, menjawab kebutuhan personalisasi pengguna.

---

### 🎯 Problem Statement 2:
**Bagaimana memahami preferensi pengguna hanya berdasarkan film yang telah mereka tonton dan beri rating?**

**Evaluasi:**
- Pada **Content-Based Filtering**, preferensi pengguna dibentuk dari genre film yang telah diberi rating tinggi.
- Kemudian dilakukan perhitungan **cosine similarity** antar film untuk mengukur kemiripan konten.
- Evaluasi kuantitatif dilakukan menggunakan metrik:
  - **Precision@10**
  - **Recall@10**
  - **NDCG@10**

**Dampak:**
- Model berhasil menyarankan film berdasarkan genre yang sering dipilih user sebelumnya, relevan dengan riwayat rating.

---

### 🎯 Problem Statement 3:
**Bagaimana menyarankan film baru yang belum ditonton pengguna, namun relevan dengan minat mereka?**

**Evaluasi:**
- Sistem hanya menyarankan film yang belum pernah ditonton oleh pengguna.
- Film yang direkomendasikan dipilih berdasarkan kemiripan konten (genre).
- Keberhasilan rekomendasi diukur dengan **Recall@10** dan **NDCG@10**: semakin tinggi nilainya, semakin tepat sasaran rekomendasinya.

**Dampak:**
- Jika metrik evaluasi menunjukkan skor rendah, maka kemungkinan preferensi belum terdeteksi dengan baik. Hal ini bisa diperbaiki dengan menambah jumlah interaksi (rating) dari pengguna.

---

## ✅ Goals Achievement

| Goals                                                                 | Status     | Penjelasan |
|----------------------------------------------------------------------|------------|------------|
| Membangun sistem rekomendasi otomatis dan personal                   | ✅ Terpenuhi | Dua model telah dibangun dan diuji |
| Memahami preferensi user berdasarkan riwayat rating                  | ✅ Terpenuhi | CBF menggunakan genre dari film yang disukai user |
| Menghasilkan rekomendasi film relevan yang belum ditonton pengguna  | ⚠️ Sebagian | Masih perlu evaluasi jika skor Precision/Recall rendah |

---

## 📊 Summary of Evaluation Metrics

### Collaborative Filtering (SVD)
- **RMSE**: _Contoh_ ` 0.8732`
- **MAE**: _Contoh_ `0.671`

### Content-Based Filtering
- **Precision@10**: `0.0`
- **Recall@10**: `0.0`
- **NDCG@10**: `0.0`

> Catatan: Nilai 0.0 menunjukkan bahwa film rekomendasi belum cukup relevan dengan film yang benar-benar disukai user. Hal ini bisa disebabkan oleh user yang memiliki sedikit rating atau genre film yang terlalu bervariasi.

---

## 💼 Relevansi Terhadap Bisnis

- **Collaborative Filtering** cocok untuk pengguna aktif dengan banyak rating karena memanfaatkan pola komunitas.
- **Content-Based Filtering** lebih cocok untuk cold-start user karena fokus pada metadata konten film.
- Evaluasi dengan metrik seperti Precision@K dan NDCG@K penting untuk mengetahui **seberapa besar potensi model dalam meningkatkan kepuasan pengguna** dan retensi dalam platform layanan film.

---
"""